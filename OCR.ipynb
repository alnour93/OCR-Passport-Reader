{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWshAUsLXDEf"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we use two distinct Optical Character Recognition (OCR) methods to handle different types of text extraction tasks. Each approach is tailored to address specific needs based on the nature of the text and the format of the documents. Here's a breakdown of the two OCR functions and their purposes:\n",
        "\n",
        "## 1. MRZ OCR for Passports/Documents\n",
        "\n",
        "### Purpose\n",
        "\n",
        "The **MRZ OCR** function is designed specifically for reading Machine Readable Zones (MRZ) found in passports and similar documents. MRZ is a standardized area in these documents that contains critical information in a fixed format, making it ideal for specialized OCR.\n",
        "\n",
        "\n",
        "### Why MRZ OCR?\n",
        "\n",
        "The MRZ area has a well-defined format, which simplifies the extraction process. Using a dedicated function for MRZ allows for precise extraction of essential personal information from passports and documents.\n",
        "\n",
        "## 2. Comprehensive OCR for General English Text\n",
        "\n",
        "### Purpose\n",
        "\n",
        "The **Comprehensive OCR** function is used for extracting general English text from various types of documents and images. This approach is well-suited for processing documents with varied text layouts and extracting English paragraphs of text.\n",
        "\n",
        "### Why Comprehensive OCR?\n",
        "\n",
        "For documents with varied text layouts and general English text, a comprehensive OCR approach is necessary. It allows for flexible and adaptable text extraction, accommodating diverse text structures and content types in English paragraphs.\n",
        "\n",
        "## Summary\n",
        "\n",
        "By employing both MRZ-specific and comprehensive OCR functions, we can effectively handle different text extraction needs:\n",
        "\n",
        "- **MRZ OCR** for structured and standardized document with machine readable zones like passports and government IDs, etc..., ensuring accurate extraction of critical information\n",
        "- **Comprehensive OCR** for general English text extraction tasks, providing flexibility and adaptability for documents with varied text layouts and paragraph structures.\n",
        "\n",
        "This dual approach ensures that we can address a wide range of text extraction challenges efficiently and accurately.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0RrM7qSAP6a",
        "outputId": "d0a789ce-29bf-43d4-d8d9-071b35adc12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [4 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\u001b[0m\r                                                                               \rIgn:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,210 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,129 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,420 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,378 kB]\n",
            "Fetched 16.1 MB in 3s (5,576 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,272 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123589 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m420.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for PassportEye (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Tesseract OCR engine using the package manager\n",
        "!sudo apt update  # Update package lists for upgrades and new package installations\n",
        "!sudo apt install -y tesseract-ocr  # Install Tesseract OCR with automatic confirmation\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install pytesseract  # Python wrapper for Tesseract OCR\n",
        "!pip install -q easyocr  # EasyOCR library for Optical Character Recognition\n",
        "!pip install -q PassportEye  # Library for parsing and OCR of passport MRZs\n",
        "!pip install -q keras_ocr  # Keras-based Optical Character Recognition library\n",
        "!pip install -q pyspellchecker  # Simple spell checking library\n",
        "!pip install -q nltk  # Natural Language Toolkit for text processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebhNq1wbAKRz"
      },
      "source": [
        "<h3 style='font-weight: bold'>Import necesary packages</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNR4thVjAKR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c67238a-8f5e-40f3-8a6a-f39122340e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import string as st\n",
        "from dateutil import parser\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from passporteye import read_mrz\n",
        "import easyocr\n",
        "from spellchecker import SpellChecker\n",
        "import difflib\n",
        "import datetime\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import warnings\n",
        "\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhIEVXgnAKR5"
      },
      "source": [
        "<h3 style='font-weight: bold'>Load easyOCR engine</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPuRzLAIAKR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24945598-916a-4833-a888-f1ea83c2ebfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ],
      "source": [
        "# lOAD OCR ENGINE (easyOCR)\n",
        "reader=easyocr.Reader(lang_list=['en'], gpu=True)  # Enable gpu if available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJOjpGqAKR7"
      },
      "source": [
        "# **MRZ OCR** (For passports and documents with machine readable zones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz3ZYBtbaJvB"
      },
      "source": [
        "# Explanation of Functions and OCR Method\n",
        "\n",
        "## 1. `parse_date`\n",
        "\n",
        "### Purpose\n",
        "Parses a date string and formats it into 'DD/MM/YYYY'. Includes an option to correct the year if it appears to be in the future.\n",
        "\n",
        "### Parameters\n",
        "- `string` (str): The date string to parse.\n",
        "- `fix_year` (bool): If `True`, adjusts the year if it is greater than the current year.\n",
        "\n",
        "### Returns\n",
        "- `str`: The parsed date in 'DD/MM/YYYY' format.\n",
        "\n",
        "### Details\n",
        "- Uses `parser.parse` from the `dateutil` library to interpret the date string in a year-first format.\n",
        "- If `fix_year` is enabled and the year is in the future, adjusts the year by subtracting 100 years.\n",
        "- Returns the date in a standardized format.\n",
        "\n",
        "## 2. `clean`\n",
        "\n",
        "### Purpose\n",
        "Cleans a string by removing all non-alphanumeric characters and converting it to uppercase.\n",
        "\n",
        "### Parameters\n",
        "- `string` (str): The string to clean.\n",
        "\n",
        "### Returns\n",
        "- `str`: The cleaned string.\n",
        "\n",
        "### Details\n",
        "- Removes characters that are not letters or digits.\n",
        "- Converts the string to uppercase for consistency.\n",
        "\n",
        "## 3. `get_gender`\n",
        "\n",
        "### Purpose\n",
        "Normalizes the gender code from a given input.\n",
        "\n",
        "### Parameters\n",
        "- `code` (str): The gender code to interpret. Expected values are 'M', 'F', or other values.\n",
        "\n",
        "### Returns\n",
        "- `str`: 'M' for male, 'F' for female, or an empty string if the code is not recognized.\n",
        "\n",
        "### Details\n",
        "- Converts the code to uppercase and validates it.\n",
        "- Returns 'M' or 'F' based on the input or '' if the input does not match expected values.\n",
        "\n",
        "## 4. `print_data`\n",
        "\n",
        "### Purpose\n",
        "Prints the key-value pairs from a dictionary in a formatted manner.\n",
        "\n",
        "### Parameters\n",
        "- `data` (dict): A dictionary containing the data to be printed.\n",
        "\n",
        "### Details\n",
        "- Replaces underscores with spaces and capitalizes the first letter of each word in the keys.\n",
        "- Prints each key-value pair in a readable format.\n",
        "\n",
        "## 5. `ocr`\n",
        "\n",
        "### Purpose\n",
        "Extracts and processes personal information from a passport image using OCR.\n",
        "\n",
        "### Parameters\n",
        "- `img_name` (str): Path to the passport image.\n",
        "\n",
        "### Returns\n",
        "- `dict`: Extracted personal information.\n",
        "\n",
        "### Details\n",
        "\n",
        "1. **Extract MRZ from Image**:\n",
        "   - Uses `read_mrz` to extract the MRZ (Machine Readable Zone) from the passport image.\n",
        "   - Saves the MRZ Region of Interest (ROI) to a temporary file.\n",
        "\n",
        "2. **Read and Preprocess MRZ Image**:\n",
        "   - Loads and resizes the MRZ image for OCR processing.\n",
        "   - Defines allowed characters for OCR and reads text using EasyOCR.\n",
        "\n",
        "3. **Process MRZ Lines**:\n",
        "   - Processes MRZ lines based on their structure and type:\n",
        "     - **Type 1**: Typically has 3 lines with specific lengths. Processes the document type, issuing country, document number, personal number, date of birth, gender, expiration date, and nationality.\n",
        "     - **Type 2**: Typically has 2 lines with varying lengths. Processes the document type, issuing country, surname, name, document number, nationality, date of birth, gender, expiration date, and personal number.\n",
        "     - **Type 3**: Typically has 2 lines with different formatting. Processes the passport type, issuing country, surname, name, passport number, nationality, date of birth, gender, expiration date, and personal number.\n",
        "\n",
        "4. **Extract Personal Information**:\n",
        "   - Extracts and formats personal details such as name, surname, gender, date of birth, nationality, passport type, passport number, issuing country, expiration date, and personal number.\n",
        "   - Cleans and formats the extracted data.\n",
        "\n",
        "5. **Clean Up**:\n",
        "   - Deletes the temporary image file used for processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJTNp8koAKR7"
      },
      "outputs": [],
      "source": [
        "def parse_date(string, fix_year=False):\n",
        "    \"\"\"\n",
        "    Parses a date string and optionally fixes the year if it's in the future.\n",
        "\n",
        "    Parameters:\n",
        "    - string (str): The date string to parse.\n",
        "    - fix_year (bool): If True, adjusts the year if it is greater than the current year.\n",
        "\n",
        "    Returns:\n",
        "    - str: The parsed date in 'DD/MM/YYYY' format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        date = parser.parse(string, yearfirst=True).date()\n",
        "        if fix_year and date.year > datetime.datetime.now().year:\n",
        "            date = date.replace(year=date.year - 100)\n",
        "        return date.strftime('%d/%m/%Y')\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing date: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean(string):\n",
        "    \"\"\"\n",
        "    Cleans a string by removing all non-alphanumeric characters and converting to uppercase.\n",
        "\n",
        "    Parameters:\n",
        "    - string (str): The string to clean.\n",
        "\n",
        "    Returns:\n",
        "    - str: The cleaned string.\n",
        "    \"\"\"\n",
        "    return ''.join([i for i in string if i.isalnum()]).upper()\n",
        "\n",
        "def get_gender(code):\n",
        "    \"\"\"\n",
        "    Returns the normalized gender code from a given input.\n",
        "\n",
        "    Parameters:\n",
        "    - code (str): The gender code to interpret. Expected to be 'M', 'F', or other values.\n",
        "\n",
        "    Returns:\n",
        "    - str: 'M' for male, 'F' for female, or 'Unknown' if the code is not recognized or provided.\n",
        "    \"\"\"\n",
        "    normalized_code = code.upper()\n",
        "    return normalized_code if normalized_code in ['M', 'F'] else ''\n",
        "\n",
        "def print_data(data):\n",
        "    \"\"\"\n",
        "    Prints the key-value pairs from a dictionary in a formatted manner.\n",
        "\n",
        "    Parameters:\n",
        "    - data (dict): A dictionary containing the data to be printed.\n",
        "    \"\"\"\n",
        "    for key, value in data.items():\n",
        "        formatted_key = key.replace('_', ' ').capitalize()\n",
        "        print(f'{formatted_key}\\t:\\t{value}')\n",
        "\n",
        "def process_mrz_type1(lines):\n",
        "    \"\"\"\n",
        "    Processes MRZ lines of type 1 to extract user information.\n",
        "\n",
        "    Parameters:\n",
        "    - lines (list): List of MRZ lines extracted from the image.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Extracted user information.\n",
        "    \"\"\"\n",
        "    user_info = {}\n",
        "\n",
        "    # Process Row 1\n",
        "    user_info['document_type'] = clean(lines[0][0:1])\n",
        "    user_info['document_type'] += clean(lines[0][1:2])  # Type character (e.g., I, A, or C)\n",
        "    user_info['issuing_country'] = clean(lines[0][2:5])  # Issuing Country (ISO 3166-1 code)\n",
        "    user_info['document_number'] = clean(lines[0][5:14])  # Document Number\n",
        "    # Skip Check Digit over Document Number (position 15) and Optional (16-30)\n",
        "\n",
        "    # Process Row 2\n",
        "    user_info['date_of_birth'] = parse_date(lines[1][0:6], fix_year=True)  # Date of Birth (YYMMDD)\n",
        "    user_info['gender'] = get_gender(lines[1][7:8])  # Sex (M, F, or <)\n",
        "    user_info['expiration_date'] = parse_date(lines[1][8:14])  # Expiration Date (YYMMDD)\n",
        "    user_info['nationality'] = clean(lines[1][15:18])  # Nationality\n",
        "    # Skip Check Digit over Expiration Date (position 15) and Optional1 (19-29)\n",
        "\n",
        "    # Process Row 3\n",
        "    names = lines[2].replace('<', ' ').strip().split()\n",
        "    user_info['surname'] = names[0] if names else ''\n",
        "    user_info['name'] = ' '.join(names[1:]) if len(names) > 1 else ''\n",
        "\n",
        "    return user_info\n",
        "\n",
        "def process_mrz_type2(lines):\n",
        "    \"\"\"\n",
        "    Processes MRZ lines of type 2 to extract user information.\n",
        "\n",
        "    Parameters:\n",
        "    - lines (list): List of MRZ lines extracted from the image.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Extracted user information.\n",
        "    \"\"\"\n",
        "    user_info = {}\n",
        "    user_info['document_type'] = clean(lines[0][0:2])\n",
        "    user_info['issuing_country'] = clean(lines[0][2:5])\n",
        "    names = lines[0][5:].replace('<', ' ').split()\n",
        "    user_info['surname'] = names[0] if names else ''\n",
        "    user_info['name'] = ' '.join(names[1:]) if len(names) > 1 else ''\n",
        "    user_info['document_number'] = clean(lines[1][0:9])\n",
        "    user_info['nationality'] = clean(lines[1][10:13])\n",
        "    user_info['date_of_birth'] = parse_date(lines[1][13:19], fix_year=True)\n",
        "    user_info['gender'] = get_gender(lines[1][20])\n",
        "    user_info['expiration_date'] = parse_date(lines[1][21:27])\n",
        "    user_info['personal_number'] = clean(lines[1][28:35])\n",
        "    return user_info\n",
        "\n",
        "def process_mrz_type3(lines):\n",
        "    \"\"\"\n",
        "    Processes MRZ lines of type 3 to extract user information.\n",
        "\n",
        "    Parameters:\n",
        "    - lines (list): List of MRZ lines extracted from the image.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Extracted user information.\n",
        "    \"\"\"\n",
        "    user_info = {}\n",
        "    user_info['passport_type'] = clean(lines[0][0:2])\n",
        "    user_info['issuing_country'] = clean(lines[0][2:5])\n",
        "    names = lines[0][5:44].replace('<', ' ').split()\n",
        "    user_info['surname'] = names[0] if names else ''\n",
        "    user_info['name'] = ' '.join(names[1:]) if len(names) > 1 else ''\n",
        "    user_info['passport_number'] = clean(lines[1][0:9])\n",
        "    user_info['nationality'] = clean(lines[1][10:13])\n",
        "    user_info['date_of_birth'] = parse_date(lines[1][13:19], fix_year=True)\n",
        "    user_info['gender'] = get_gender(lines[1][20])\n",
        "    user_info['expiration_date'] = parse_date(lines[1][21:27])\n",
        "    user_info['personal_number'] = clean(lines[1][28:42])\n",
        "    return user_info\n",
        "\n",
        "def ocr(img_name):\n",
        "    \"\"\"\n",
        "    Extracts and processes personal information from the passport image.\n",
        "\n",
        "    Parameters:\n",
        "    - img_name (str): Path to the passport image.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Extracted personal information.\n",
        "    \"\"\"\n",
        "    user_info = {}\n",
        "    temp_image_path = 'tmp.png'\n",
        "\n",
        "    # Extract MRZ from image\n",
        "    mrz = read_mrz(img_name, save_roi=True)\n",
        "    if not mrz:\n",
        "        print(f'Machine cannot read image {img_name}.')\n",
        "        return user_info\n",
        "\n",
        "    # Save and process MRZ image\n",
        "    mpimg.imsave(temp_image_path, mrz.aux['roi'], cmap='gray')\n",
        "    img = cv2.imread(temp_image_path)\n",
        "    img = cv2.resize(img, None, fx=2, fy=2)  # Increase resolution for better OCR\n",
        "\n",
        "    # Define allowed characters for OCR\n",
        "    allowlist = st.ascii_letters + st.digits + '< '\n",
        "    lines = reader.readtext(img, paragraph=False, detail=0, allowlist=allowlist)\n",
        "\n",
        "    # Process MRZ lines based on their structure\n",
        "    if len(lines) == 3 and all(len(line) >= 30 for line in lines):\n",
        "        user_info = process_mrz_type1(lines)\n",
        "    elif len(lines) == 2:\n",
        "        if all(len(line) >= 36 for line in lines):\n",
        "            user_info = process_mrz_type2(lines)\n",
        "        elif all(len(line) >= 44 for line in lines):\n",
        "            user_info = process_mrz_type3(lines)\n",
        "    else:\n",
        "        print(\"Unrecognized MRZ format\")\n",
        "\n",
        "    # Clean up temporary image file\n",
        "    os.remove(temp_image_path)\n",
        "    return user_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqYhCulvUfrz"
      },
      "source": [
        "# Example Usage of MRZ OCR Function\n",
        "\n",
        "The `ocr` function is designed to extract personal information from passport images by specifically reading and interpreting the MRZ (Machine Readable Zone) text. It returns structured data related to personal information found in the MRZ area.\n",
        "\n",
        "**Usage**\n",
        "\n",
        "- To use the OCR functionality, call the `ocr` function with the path to the image file. This function will process the MRZ area of the image to extract personal details.\n",
        "- The extracted personal information will be returned as a structured dictionary. The MRZ image will be saved temporarily, processed, and cleaned up after extraction.\n",
        "\n",
        "**Note:** Uncomment the following code block to use the ocr function. Replace 'image_path' with the actual path to your image file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "werpXX0W2y7H"
      },
      "outputs": [],
      "source": [
        "#img_name = 'image_path'\n",
        "#%time data = ocr(img_name)\n",
        "#print_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IboiwFapHuoH"
      },
      "source": [
        "# **Testing Framework:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OEQzrmgc5Cu"
      },
      "source": [
        "## Accuracy Calculation Functions\n",
        "\n",
        "These functions are designed to evaluate the performance of OCR (Optical Character Recognition) systems by comparing the recognized text with the ground truth text. They calculate and print both character and word accuracies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSOsQZ1--sUw"
      },
      "outputs": [],
      "source": [
        "def character_accuracy(gt, rec):\n",
        "    \"\"\"\n",
        "    Calculate character accuracy between ground truth and recognized text.\n",
        "\n",
        "    Args:\n",
        "        gt (str): Ground truth text.\n",
        "        rec (str): Recognized text.\n",
        "\n",
        "    Returns:\n",
        "        float: Character accuracy percentage.\n",
        "    \"\"\"\n",
        "    correct_chars = sum(1 for gt_char, rec_char in zip(gt, rec) if gt_char == rec_char)\n",
        "    total_chars = len(gt)\n",
        "    return (correct_chars / total_chars) * 100 if total_chars > 0 else 0\n",
        "\n",
        "def word_accuracy(gt, rec):\n",
        "    \"\"\"\n",
        "    Calculate word accuracy between ground truth and recognized text.\n",
        "\n",
        "    Args:\n",
        "        gt (str): Ground truth text.\n",
        "        rec (str): Recognized text.\n",
        "\n",
        "    Returns:\n",
        "        float: Word accuracy percentage.\n",
        "    \"\"\"\n",
        "    gt_words = gt.split()\n",
        "    rec_words = rec.split()\n",
        "    correct_words = sum(1 for gt_word, rec_word in zip(gt_words, rec_words) if gt_word == rec_word)\n",
        "    total_words = len(gt_words)\n",
        "    return (correct_words / total_words) * 100 if total_words > 0 else 0\n",
        "\n",
        "def calculate_accuracies(gt_dict, rec_dict):\n",
        "    \"\"\"\n",
        "    Calculate and print character and word accuracies for each field in the ground truth and recognized dictionaries.\n",
        "\n",
        "    Args:\n",
        "        gt_dict (dict): Dictionary with ground truth text.\n",
        "        rec_dict (dict): Dictionary with recognized text.\n",
        "    \"\"\"\n",
        "    char_acc_total = 0\n",
        "    word_acc_total = 0\n",
        "    fields_count = 0  # Count of non-empty fields\n",
        "\n",
        "    for key in gt_dict:\n",
        "        gt = gt_dict[key].strip().lower()\n",
        "        rec = rec_dict.get(key, \"\").strip().lower()\n",
        "\n",
        "        # Skip empty ground truth fields\n",
        "        if gt == \"\":\n",
        "            continue\n",
        "\n",
        "        # Calculate accuracies\n",
        "        char_acc = character_accuracy(gt, rec)\n",
        "        word_acc = word_accuracy(gt, rec)\n",
        "        char_acc_total += char_acc\n",
        "        word_acc_total += word_acc\n",
        "        fields_count += 1\n",
        "\n",
        "        # Print field-wise accuracy\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"  Ground Truth: {gt}\")\n",
        "        print(f\"  Recognized: {rec}\")\n",
        "        print(f\"  Character Accuracy: {char_acc:.2f}%\")\n",
        "        print(f\"  Word Accuracy: {word_acc:.2f}%\\n\")\n",
        "\n",
        "    # Print overall accuracies\n",
        "    if fields_count > 0:\n",
        "        overall_char_acc = char_acc_total / fields_count\n",
        "        overall_word_acc = word_acc_total / fields_count\n",
        "\n",
        "        print(f\"Overall Character Accuracy: {overall_char_acc:.2f}%\")\n",
        "        print(f\"Overall Word Accuracy: {overall_word_acc:.2f}%\")\n",
        "    else:\n",
        "        print(\"No non-empty fields to calculate accuracy.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKBhBYpnVRXm"
      },
      "source": [
        "## Gathering Actual Data from User Input\n",
        "\n",
        "To evaluate the OCR results, you need to compare them with the actual data. Use the following code snippet to collect the actual data from the user.\n",
        "\n",
        "### Code Explanation\n",
        "\n",
        "The code snippet prompts the user to enter various pieces of information related to the passport or document. Each input is converted to uppercase (where applicable) and stored in a dictionary called `actual_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCO03mRIUXd"
      },
      "outputs": [],
      "source": [
        "# Get actual data from user input\n",
        "actual_data = {}\n",
        "print(\"Enter the actual data:\")\n",
        "actual_data['name'] = input(\"Name: \").upper()\n",
        "actual_data['surname'] = input(\"Surname: \").upper()\n",
        "actual_data['gender'] = input(\"Gender (M/F): \").upper()\n",
        "actual_data['date_of_birth'] = input(\"Date of Birth (DD/MM/YYYY): \")\n",
        "actual_data['nationality'] = input(\"Nationality: \").upper()\n",
        "actual_data['passport_type'] = input(\"Passport Type: \").upper()\n",
        "actual_data['passport_number'] = input(\"Passport Number: \")\n",
        "actual_data['issuing_country'] = input(\"Issuing Country: \").upper()\n",
        "actual_data['expiration_date'] = input(\"Expiration Date (DD/MM/YYYY): \")\n",
        "actual_data['personal_number'] = input(\"Personal Number: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4debU6VfYG"
      },
      "source": [
        "## Calculate and Display Accuracies\n",
        "\n",
        "After gathering the actual data and extracting the OCR results, you can calculate and display the accuracy of the OCR results compared to the actual data. Use the `calculate_accuracies` function to compute both character and word accuracies for each field and overall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85CwDrRrIMl7"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracies\n",
        "calculate_accuracies(actual_data, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm_5LLHMIb5Q"
      },
      "source": [
        "# **Comprehensive OCR System**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv1G_PtBWR3F"
      },
      "source": [
        "### Imports and Initialization\n",
        "\n",
        "1. **Imports**:\n",
        "    - `cv2`, `numpy`, `easyocr`, `json`, `nltk`, `matplotlib.pyplot`: Libraries for image processing, OCR, natural language processing, and visualization.\n",
        "    - `SpellChecker` from `spellchecker`: For spell checking.\n",
        "    - `word_tokenize` and `pos_tag` from `nltk.tokenize` and `nltk.tag`: For text tokenization and part-of-speech tagging.\n",
        "\n",
        "2. **NLTK Downloads**:\n",
        "    - Downloads necessary NLTK data for tokenization and POS tagging.\n",
        "\n",
        "3. **Spell Checker Initialization**:\n",
        "    - Initializes the spell checker to correct spelling errors.\n",
        "\n",
        "### Functions\n",
        "\n",
        "1. **`show_image(title, image)`**:\n",
        "    - **Purpose**: Displays an image with a given title.\n",
        "    - **Parameters**:\n",
        "        - `title`: Title of the image window.\n",
        "        - `image`: Image data in numpy array format.\n",
        "    - **Functionality**:\n",
        "        - Uses `matplotlib` to display the image with a title.\n",
        "        - Converts the image from BGR to RGB for correct color representation.\n",
        "\n",
        "2. **`correct_text(text)`**:\n",
        "    - **Purpose**: Corrects spelling in the provided text, ignoring proper nouns and numbers.\n",
        "    - **Parameters**:\n",
        "        - `text`: The text to be corrected.\n",
        "    - **Functionality**:\n",
        "        - Tokenizes the text into words.\n",
        "        - Tags each word with its part-of-speech (POS).\n",
        "        - Uses the spell checker to correct misspelled words, except for proper nouns and numbers.\n",
        "\n",
        "3. **`preprocess_image(img_path)`**:\n",
        "    - **Purpose**: Preprocesses the image to prepare it for OCR.\n",
        "    - **Parameters**:\n",
        "        - `img_path`: Path to the image file.\n",
        "    - **Functionality**:\n",
        "        - Loads the image using `cv2.imread`.\n",
        "        - Resizes the image if its dimensions exceed a maximum value (`max_dim`).\n",
        "        - Converts the image to grayscale to simplify OCR processing.\n",
        "    - **Returns**:\n",
        "        - `gray_image`: The preprocessed grayscale image.\n",
        "        - `original_image`: The original color image.\n",
        "\n",
        "4. **`ocr2(img_path)`**:\n",
        "    - **Purpose**: Extracts and corrects text from an image using OCR, then draws bounding boxes around detected text.\n",
        "    - **Parameters**:\n",
        "        - `img_path`: Path to the image file.\n",
        "    - **Functionality**:\n",
        "        - **Preprocessing**: Calls `preprocess_image` to get the grayscale and original images.\n",
        "        - **OCR Processing**: Initializes the `easyocr.Reader` and uses it to detect text in the grayscale image.\n",
        "        - **Text Correction and Annotation**:\n",
        "            - For each detected text segment, corrects the text using `correct_text`.\n",
        "            - Draws a bounding box around the detected text in the original image.\n",
        "            - Adds the corrected text and bounding box data to a JSON list.\n",
        "        - **Display**: Uses `show_image` to display the original image with annotated text.\n",
        "    - **Returns**:\n",
        "        - `json_data`: A list of dictionaries containing the detected text, bounding boxes, and confidence scores.\n",
        "\n",
        "### Summary\n",
        "\n",
        "1. **Image Preprocessing**: Resize and convert the image to grayscale for OCR.\n",
        "2. **OCR Processing**: Detect text from the preprocessed image.\n",
        "3. **Text Correction**: Improve the detected text by correcting spelling errors.\n",
        "4. **Annotation**: Draw bounding boxes around detected text on the original image.\n",
        "5. **Display and Output**: Show the annotated image and return the JSON data with text, bounding boxes, and confidence scores.\n",
        "\n",
        "This code helps in processing images, extracting text, and providing an annotated view of the detected text, making it suitable for tasks like verifying OCR accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN6kDXwiicL0",
        "outputId": "ccebd572-ddee-4177-8371-8e45e7ab4d7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import easyocr\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from spellchecker import SpellChecker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Initialize the spell checker\n",
        "spell = SpellChecker()\n",
        "\n",
        "def show_image(title, image):\n",
        "    \"\"\"\n",
        "    Displays an image with a title.\n",
        "\n",
        "    Parameters:\n",
        "    - title (str): Title of the image.\n",
        "    - image (numpy.ndarray): The image to display.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(title)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def correct_text(text):\n",
        "    \"\"\"\n",
        "    Corrects the text using spell checker, except for proper nouns and numbers.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The text to correct.\n",
        "\n",
        "    Returns:\n",
        "    - str: The corrected text.\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Perform part-of-speech tagging\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    corrected_words = []\n",
        "    for word, tag in tagged:\n",
        "        # Only correct words that are not proper nouns (NNP) or numbers (CD)\n",
        "        if tag not in ['NNP', 'NNPS']:\n",
        "            corrected_word = spell.correction(word)\n",
        "            corrected_words.append(corrected_word if corrected_word else word)\n",
        "        else:\n",
        "            corrected_words.append(word)\n",
        "\n",
        "    return ' '.join(corrected_words)\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    \"\"\"\n",
        "    Preprocesses the image for OCR.\n",
        "\n",
        "    Parameters:\n",
        "    - img_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    - image (numpy.ndarray): The preprocessed image.\n",
        "    \"\"\"\n",
        "    # Load and resize the image\n",
        "    image = cv2.imread(img_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Error: Could not load image {img_path}\")\n",
        "\n",
        "    # Resize the image\n",
        "    height, width = image.shape[:2]\n",
        "    max_dim = 1000  # Resize to a maximum dimension of 1000 pixels\n",
        "    if max(height, width) > max_dim:\n",
        "        scale = max_dim / float(max(height, width))\n",
        "        new_size = (int(width * scale), int(height * scale))\n",
        "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_image, image\n",
        "\n",
        "def ocr2(img_path):\n",
        "    \"\"\"\n",
        "    Processes an image to extract and correct text using OCR.\n",
        "\n",
        "    Parameters:\n",
        "    - img_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    - json_data (list): List of dictionaries containing text, bounding boxes, and confidence scores.\n",
        "    \"\"\"\n",
        "    gray_image, original_image = preprocess_image(img_path)\n",
        "\n",
        "    # Initialize the OCR reader\n",
        "    reader = easyocr.Reader(['en'])\n",
        "\n",
        "    # Read text from preprocessed image\n",
        "    results = reader.readtext(gray_image)\n",
        "\n",
        "    json_data = []\n",
        "\n",
        "    if results:\n",
        "        # Draw bounding boxes and corrected text on the original image\n",
        "        for (bbox, text, prob) in results:\n",
        "            corrected_text = correct_text(text)\n",
        "\n",
        "            # Draw bounding box\n",
        "            p0, p1, p2, p3 = bbox\n",
        "            p0 = tuple(map(int, p0))\n",
        "            p1 = tuple(map(int, p1))\n",
        "            p2 = tuple(map(int, p2))\n",
        "            p3 = tuple(map(int, p3))\n",
        "\n",
        "            cv2.rectangle(original_image, p0, p2, (0, 255, 0), 2)\n",
        "\n",
        "            # Put corrected text label\n",
        "            cv2.putText(original_image, corrected_text, p0, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Add data to JSON list\n",
        "            json_data.append({\n",
        "                \"text\": corrected_text,\n",
        "                \"bounding_box\": [p0, p1, p2, p3],\n",
        "                \"confidence\": prob\n",
        "            })\n",
        "\n",
        "        # Display the image with bounding boxes\n",
        "        show_image(\"Image with Bounding Boxes\", original_image)\n",
        "\n",
        "    else:\n",
        "        print(\"No text detected by OCR.\")\n",
        "\n",
        "    # Return JSON data\n",
        "    return json_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asUqhlMybrJc"
      },
      "source": [
        "**Usage:**\n",
        "\n",
        "To use the OCR functionality, call the ocr2 function with the path to the image file.\n",
        "The processed image with bounding boxes will be displayed, and the recognized text along with bounding box coordinates and confidence scores will be returned as a JSON object.\n",
        "\n",
        "**Note:** Uncomment the following code block to use the ocr function. Replace 'image_path' with the actual path to your image file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHgdhup9LBL3"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "\n",
        "#img_path = 'image_path'  # Change to your image path\n",
        "#%time results = ocr2(img_path)\n",
        "#print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4094897,
          "sourceId": 7103355,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}